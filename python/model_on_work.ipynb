{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871626f1-9902-43df-b3d0-eec6a2cbbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\supnova\\AppData\\Local\\Temp\\pip-install-6ykx2xzk\\pytorch_8f96f9362afe4f5684c9f335a671142a\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\supnova\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#! pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3375d981-7fbc-4624-8c92-3a849513c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8beaf2f-775b-4e23-8d36-7d8528fd079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_g = pd.read_csv('./p_b_growth_data.csv')\n",
    "df_b_e = pd.read_csv('./p_b_ev_data.csv')\n",
    "\n",
    "\n",
    "df_c_g = pd.read_csv('./p_c_growth_data.csv')\n",
    "df_c_e = pd.read_csv('./p_c_ev_data.csv')\n",
    "\n",
    "df_d_g = pd.read_csv('./p_d_growth_data.csv')\n",
    "df_d_e = pd.read_csv('./p_d_ev_data.csv')\n",
    "df_e = pd.read_csv('./p_e_growth_data.csv')\n",
    "np.set_printoptions(precision = 3, suppress = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fc988cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.966    5.999 1021.772   81.508   15.869  116.58 ]]\n",
      "\n",
      " [[   1.       6.    1022.634   81.252   13.338  112.797]]\n",
      "\n",
      " [[   1.02     5.964 1022.623   96.81    14.017  104.153]]\n",
      "\n",
      " [[   0.842    6.072  968.744   88.85    16.22    88.791]]\n",
      "\n",
      " [[   0.93     6.067 1021.985   86.565   13.912   73.803]]\n",
      "\n",
      " [[   1.       6.    1022.464   87.817   12.487   69.489]]\n",
      "\n",
      " [[   0.868    5.881  431.556   72.86    13.113   87.262]]\n",
      "\n",
      " [[   0.919    5.675  443.675   70.096   11.676   57.994]]\n",
      "\n",
      " [[   1.       5.999  441.701   87.736   12.61    64.118]]\n",
      "\n",
      " [[   1.       6.     369.502   95.794   12.201   33.891]]\n",
      "\n",
      " [[   1.       6.     407.886   90.979   12.171   70.555]]\n",
      "\n",
      " [[   0.       6.     476.146   93.1     12.733   84.293]]\n",
      "\n",
      " [[   0.662    5.885  439.828   94.561   10.912   51.296]]\n",
      "\n",
      " [[   0.866    6.     476.647   93.409   10.832   63.071]]\n",
      "\n",
      " [[   0.725    5.998  489.454   95.83    10.453   47.067]]\n",
      "\n",
      " [[   1.       6.     476.963   92.043   11.018   77.267]]\n",
      "\n",
      " [[   1.       5.998  437.946   91.656   12.477   87.184]]\n",
      "\n",
      " [[   1.       6.     461.885   90.199   11.385   80.646]]\n",
      "\n",
      " [[   1.       6.     432.598   90.217   12.837   83.319]]\n",
      "\n",
      " [[   1.       6.     461.908   95.77    10.084   35.567]]\n",
      "\n",
      " [[   1.097    6.312  451.696   85.805   12.833  103.82 ]]\n",
      "\n",
      " [[   1.029    6.091  436.591   83.267   12.636  118.523]]\n",
      "\n",
      " [[   1.       6.     421.102   86.629   12.927  132.665]]\n",
      "\n",
      " [[   0.852    6.     409.814   84.588   15.008  136.128]]\n",
      "\n",
      " [[   0.987    6.009  459.829   87.008   13.279   94.834]]\n",
      "\n",
      " [[   0.606    6.005  444.643   82.282   14.808  121.788]]\n",
      "\n",
      " [[   0.865    5.99   483.663   76.729   16.35   177.642]]\n",
      "\n",
      " [[   0.967    6.     581.26    98.814   14.465  125.848]]\n",
      "\n",
      " [[   1.       6.     583.1     98.643   14.34   116.301]]]\n",
      "(29, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "train_x = df_b_e.loc[3:,'supplyEC':].to_numpy()\n",
    "train_x = train_x.reshape(29,1,6)\n",
    "print(train_x)\n",
    "print(np.shape(train_x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daf177ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.588    5.994   24.215    3.543    0.822    8.141]]\n",
      "\n",
      " [[   0.56     5.998    0.       0.       0.       0.   ]]\n",
      "\n",
      " [[   0.222    5.998  187.082   31.238    6.743   32.452]]\n",
      "\n",
      " [[   0.607    5.991  460.591   71.573   16.044   77.296]]\n",
      "\n",
      " [[   0.398    5.994  672.304   73.564   15.904   69.889]]\n",
      "\n",
      " [[   0.378    5.994  855.773   81.428   14.955   74.829]]\n",
      "\n",
      " [[   0.492    5.987  759.121   77.459   16.847   74.098]]\n",
      "\n",
      " [[   0.714    5.996  850.066   87.693   14.923   82.063]]\n",
      "\n",
      " [[   0.82     5.995 1751.61    81.629   14.425   71.038]]\n",
      "\n",
      " [[   0.398    6.    1010.359   84.097   13.833   84.122]]\n",
      "\n",
      " [[   0.368    6.004 1115.107   81.813   14.827   78.122]]\n",
      "\n",
      " [[   0.292    5.999 1529.133   78.721   15.042   75.103]]\n",
      "\n",
      " [[   0.348    5.999 1413.102   83.123   13.545   76.5  ]]\n",
      "\n",
      " [[   0.697    6.002 1827.624   76.945   14.982   70.28 ]]\n",
      "\n",
      " [[   0.915    5.992  680.803   77.206   15.379   72.414]]\n",
      "\n",
      " [[   0.551    5.954 1319.99    78.411   14.407   79.2  ]]\n",
      "\n",
      " [[   0.574    5.769  715.941   76.828   15.617   78.4  ]]\n",
      "\n",
      " [[   0.54     5.798  762.802   87.357   13.384   82.416]]\n",
      "\n",
      " [[   1.034    6.08   900.767   75.481   15.283   65.728]]\n",
      "\n",
      " [[   0.788    5.847  631.245   70.851   16.157   68.035]]\n",
      "\n",
      " [[   0.65     5.911  678.646   69.518   16.217   69.128]]\n",
      "\n",
      " [[   0.914    5.992  499.144   66.807   16.78    60.525]]\n",
      "\n",
      " [[   0.793    6.     415.493   73.495   16.03    78.29 ]]\n",
      "\n",
      " [[   0.745    5.996  337.967   66.136   17.797   74.282]]\n",
      "\n",
      " [[   0.2      5.993  294.169   59.27    19.444   66.544]]\n",
      "\n",
      " [[   0.64     5.999  283.529   69.497   17.242   73.219]]\n",
      "\n",
      " [[   0.755    6.     258.06    56.179   19.374   58.168]]]\n",
      "(27, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "test_x = df_d_e.loc[2:,'supplyEC':].to_numpy()\n",
    "test_x = test_x.reshape(27,1,6)\n",
    "print(test_x)\n",
    "print(np.shape(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2769d87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263.889  80.444  71.222 149.      4.556  12.256   0.      0.      0.   ]\n",
      "[[ 19.333  10.889  10.889  -4.444   0.667   3.927   0.      0.      0.   ]\n",
      " [  4.222   5.778   7.333 -18.      0.333   2.852   0.      0.      0.   ]\n",
      " [  4.     -0.556   0.     -6.778   0.778   1.808   0.      0.      0.444]\n",
      " [ -2.222   0.333   1.222  -5.222   0.667   1.356   0.667   1.222   0.556]\n",
      " [-41.     -4.556  -5.556  -5.667  -1.222   1.973   0.889   3.444   0.   ]\n",
      " [  7.556  -0.667  -0.889  16.889   0.889   1.413   0.444   1.778   0.   ]\n",
      " [  6.889  -2.333  -0.444  -2.778  -0.333   1.596  -0.778   3.333   0.   ]\n",
      " [  8.222  -1.667  -5.667   7.556   0.333   0.156   0.222   1.111   0.   ]\n",
      " [-16.667  -1.444  -3.667   0.      0.444  -0.469   0.111   0.556   0.   ]\n",
      " [ 17.528  -2.722  -4.944  30.194   0.389  -1.279  -1.556  -2.944   0.   ]\n",
      " [ 23.028   3.278   7.5    13.472   0.167   0.864   0.     -0.833   0.   ]\n",
      " [-12.889  -5.333  -5.667 -10.     -0.556  -0.362   0.     -1.444   0.   ]\n",
      " [  0.667   4.333   1.889  -4.556  -0.111  -0.502   0.     -2.556   0.   ]\n",
      " [  2.333   2.778   1.      3.556   0.222   1.358   0.     -2.111   0.   ]\n",
      " [ -4.667 -18.889 -14.222 -17.111   0.889  -1.803   0.     -1.333   0.222]\n",
      " [ -1.333  -6.444  -3.778  -5.889  -1.111   2.424   0.444   4.      0.667]\n",
      " [ -2.333   2.111   0.333  -3.444   0.667  -4.263  -0.222  -1.111   0.111]\n",
      " [  2.333  -8.     -5.778  -9.667   0.889   1.264   0.222  -0.111   0.   ]\n",
      " [  0.      3.222   4.444 -10.556   0.      1.832  -0.333  -1.444   0.   ]\n",
      " [  6.      8.222   4.556  -0.444   0.     -1.197   0.222  -0.667  -1.333]\n",
      " [ -3.667  -3.667  -2.333   4.778   0.444   1.462  -0.333  -0.333   0.   ]\n",
      " [-53.778  -0.667   0.444  -8.667  -1.556  -2.103   0.      0.      1.333]\n",
      " [  5.333   9.778  13.111   6.      0.778   0.263   0.778   4.778   1.   ]\n",
      " [ 20.      4.111   6.333  22.889   1.444  -0.031   0.222   1.556   0.   ]\n",
      " [ 19.889   0.444   1.889  21.778   0.556   2.049  -1.     -1.444   0.   ]\n",
      " [ 30.778   3.667  -1.      5.111   0.      0.857   0.     -2.444   0.   ]\n",
      " [ 42.889  -1.222   0.556   7.444   1.556   0.554   0.     -2.333   0.   ]\n",
      " [  6.222   2.667   4.222  19.      0.111  -1.03    0.     -0.667   0.   ]\n",
      " [ 28.333   4.     -5.     33.667   0.889   0.487   0.333   1.778   1.   ]]\n",
      "(29, 9)\n"
     ]
    }
   ],
   "source": [
    "ty_early_g = df_b_g.loc[0,'초장(mm)':].to_numpy()\n",
    "train_y = df_b_g.loc[:,'초장(mm)':].diff(axis=0).loc[1:].to_numpy()\n",
    "\n",
    "print(ty_early_g)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be38fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164.222  68.111  56.333  51.933   4.222  13.264   0.      0.      0.   ]\n",
      "[[ 12.333  20.778  22.      6.733  -0.222   4.397   0.      0.      0.   ]\n",
      " [ -0.778   1.222   6.778   8.889   0.889   1.358   0.222   0.111   0.444]\n",
      " [ 52.333   9.111   3.111  17.111   1.      3.439   2.333   2.667   0.556]\n",
      " [ 25.111  11.222   3.444  40.778   0.222  -0.694  -0.111   3.      0.   ]\n",
      " [ 33.556   1.333  -1.111   8.778  -1.778   0.498  -0.667   4.      0.   ]\n",
      " [  4.889  -4.778  -4.667  15.778   1.      0.919  -1.667   0.444   0.   ]\n",
      " [  2.556   0.111  -1.444  -6.      0.111   0.227  -0.111  -0.222   0.   ]\n",
      " [  8.778  -0.111  -1.889   2.222   0.667   2.004   0.     -1.      0.   ]\n",
      " [  3.889  -5.778   1.444  13.778  -0.111  -0.386   0.     -1.444   0.   ]\n",
      " [ -4.556  -0.222  -8.111   1.444   0.     -0.069   0.     -1.111   0.   ]\n",
      " [  2.222  -6.889  -6.333  12.      0.444  -1.869   0.     -2.667   0.   ]\n",
      " [ -1.222  10.333   7.222 -16.444  -0.222   1.552   0.     -2.778   0.   ]\n",
      " [  0.667 -19.444 -11.889  -1.778  -0.333  -0.018   0.     -1.      0.778]\n",
      " [ -5.556  -3.111  -3.667  -4.889   0.444   1.378   0.333   5.      0.222]\n",
      " [  1.556 -12.444  -6.556  -8.556   1.333  -0.886   0.444   0.333   0.   ]\n",
      " [  3.889   0.333   1.889 -14.778  -0.111   0.358  -0.222  -0.333   0.   ]\n",
      " [ -0.444  -1.     -0.111   1.222   1.333  -0.279   0.889  -1.      0.   ]\n",
      " [ -3.111   0.222   2.889  11.111   0.333   0.367  -0.778   0.556   0.   ]\n",
      " [ -7.111   0.     -0.556 -19.556  -0.667   1.267  -0.111  -2.444  -0.889]\n",
      " [-29.667   2.444  -0.333  20.     -0.333  -3.051  -0.556   1.      0.889]\n",
      " [ -2.333   8.111   7.778   1.556   0.778   1.867   0.222   1.      1.   ]\n",
      " [ 23.333   0.889  -0.111  16.111   0.667   0.914  -0.222  -1.556   0.   ]\n",
      " [ 28.556   4.111   7.778  35.556  -1.889   2.832   0.      1.222   0.   ]\n",
      " [ 15.667   7.111   2.     -5.444   1.111  -1.266   0.     -0.778   0.   ]\n",
      " [ 22.444  -0.556   0.778  22.889  -0.889  -1.399   0.     -0.444   0.   ]\n",
      " [ -2.222   0.556   0.667 -17.444  -0.778   1.137   0.     -1.444   0.   ]\n",
      " [  7.667   3.111  -3.667  19.444   1.556  -0.844   0.     -0.667   0.   ]]\n",
      "(27, 9)\n"
     ]
    }
   ],
   "source": [
    "test_y_early_g =  df_d_g.loc[0,'초장(mm)':].to_numpy()\n",
    "test_y = df_d_g.loc[:,'초장(mm)':].diff(axis=0).loc[1:].to_numpy()\n",
    "\n",
    "print(test_y_early_g)\n",
    "print(test_y)\n",
    "print(np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec5bddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 28\n",
    "#learning_rate = 0.1\n",
    "Epochs = 100\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device: %s\"%(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd260266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c750b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03f16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=20, activation='relu', input_shape=(1,6)))\n",
    "model.add(RepeatVector(9))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=20, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cca013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c31079cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 5ms/step - loss: 7.7273\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0482\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0914\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3890\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2516\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7655\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4640\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.1488\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0086\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1902\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9489\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.8225\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.8390\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5479\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5328\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.4441\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3607\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3685\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 4.4224\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.1899\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3188\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2248\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.2449\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2761\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2641\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2369\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2963\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2555\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2588\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2571\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1684\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2433\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2249\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2292\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2130\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1853\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1973\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1985\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1935\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2628\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1456\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1300\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1533\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2114\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2064\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1784\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1634\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1729\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1872\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.1967\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2249\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1695\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 4.1626\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1278\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1411\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1217\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1160\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1733\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1468\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.2246\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1742\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1696\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1892\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1281\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1454\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1812\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1189\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1152\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1866\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1730\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1766\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1550\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1719\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1508\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1783\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1715\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1950\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1869\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1652\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1253\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1497\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1343\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1120\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1333\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1482\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1698\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1448\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1265\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1167\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1408\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1502\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1110\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1276\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1141\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.1178\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1276\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1012\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.1058\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1380\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6b634c880>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "model.fit(train_x, train_y, epochs=Epochs , batch_size=Batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d5b4d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n",
      "[[164.222  68.111  56.333  51.933   5.     13.264   0.      0.      0.   ]\n",
      " [164.337  68.272  56.529  52.155   5.     13.519   1.      1.      1.   ]\n",
      " [164.399  68.339  56.6    52.229   5.     13.596   1.      1.      1.   ]\n",
      " [164.456  68.398  56.661  52.291   5.     13.661   1.      1.      1.   ]\n",
      " [164.519  68.467  56.734  52.367   5.     13.741   1.      1.      1.   ]\n",
      " [164.52   68.4    56.616  52.215   5.     13.563   1.      1.      1.   ]\n",
      " [164.814  68.069  56.042  51.725   5.     13.507   1.      1.      1.   ]\n",
      " [164.848  67.924  55.776  51.399   4.     13.228   1.      1.      1.   ]\n",
      " [164.925  67.727  55.419  50.992   4.     12.951   1.      1.      1.   ]\n",
      " [166.134  66.789  54.857  50.965   4.     13.508   1.      1.      2.   ]\n",
      " [166.566  66.39   54.207  50.502   4.     13.595   1.      2.      2.   ]\n",
      " [167.309  65.79   53.46   50.193   4.     13.958   2.      2.      3.   ]\n",
      " [168.36   64.958  52.782  50.083   5.     14.482   2.      3.      3.   ]\n",
      " [169.347  64.172  52.072  49.934   5.     14.983   3.      4.      4.   ]\n",
      " [170.596  63.21   51.547  49.923   6.     15.545   4.      4.      4.   ]\n",
      " [170.596  63.154  51.449  49.796   5.     15.392   3.      4.      4.   ]\n",
      " [171.503  62.429  50.713  49.595   6.     15.857   4.      4.      5.   ]\n",
      " [171.517  62.42   50.691  49.564   6.     15.817   4.      4.      5.   ]\n",
      " [171.518  62.381  50.624  49.477   6.     15.707   4.      4.      5.   ]\n",
      " [172.082  61.905  49.918  49.067   5.     15.921   4.      5.      5.   ]\n",
      " [172.083  61.866  49.849  48.977   5.     15.809   4.      5.      5.   ]\n",
      " [172.084  61.799  49.731  48.826   5.     15.632   4.      5.      5.   ]\n",
      " [172.101  61.797  49.718  48.806   5.     15.605   4.      4.      5.   ]\n",
      " [172.165  61.867  49.793  48.885   5.     15.688   4.      5.      5.   ]\n",
      " [172.229  61.939  49.87   48.965   5.     15.773   4.      5.      5.   ]\n",
      " [172.293  62.01   49.946  49.045   5.     15.857   4.      5.      5.   ]\n",
      " [172.358  62.082  50.024  49.126   5.     15.942   4.      5.      5.   ]\n",
      " [172.421  62.152  50.098  49.203   6.     16.023   4.      5.      5.   ]]\n"
     ]
    }
   ],
   "source": [
    "preb_y = model.predict(test_x)\n",
    "np.set_printoptions(precision = 3, suppress = True)\n",
    "preb_y = preb_y.reshape(len(preb_y),9)\n",
    "\n",
    "#for i in range(1, len(preb_y)):\n",
    "#    preb_y[i] = \n",
    "\n",
    "preb_y = np.insert(preb_y, 0,test_y_early_g,axis=0)\n",
    "\n",
    "\n",
    "for i in range(1, len(preb_y)):\n",
    "    for j in range(9):\n",
    "        if preb_y[i-1][j] + preb_y[i][j] < 0 :\n",
    "            if i == len(preb_y)-1:\n",
    "                pass\n",
    "            else:\n",
    "                preb_y[i+1][j] = preb_y[i+1][j]+preb_y[i][j]\n",
    "            preb_y[i][j] = 0\n",
    "        else:\n",
    "            preb_y[i][j] = preb_y[i][j] + preb_y[i-1][j]\n",
    "\n",
    "for i in range(len(preb_y)):\n",
    "    for j in range(9):\n",
    "        if j == 4 or j == 6 or j == 7 or j == 8:\n",
    "            preb_y[i][j] = math.ceil(preb_y[i][j])\n",
    "print(preb_y)\n",
    "#plt.figure()\n",
    "#plt.plot(test_y, color='red', label='실제값')\n",
    "#plt.plot(preb_y, color='blue', label='예측값')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b7c7844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./vvsb_preTest_model.model\\assets\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "model.save(\"./vvsb_preTest_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b26f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
